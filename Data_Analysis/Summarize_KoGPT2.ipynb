{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarize_KoGPT2.ipynb",
      "provenance": [],
      "mount_file_id": "1OtvDxSxKAduaRSn1sfgcLMCEFKTUrXKp",
      "authorship_tag": "ABX9TyOpbWd7MOqhJuw+1AiLH9gL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dev-hottae/PINC/blob/master/Data_Analysis/Summarize_KoGPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzAoHG40BXTz",
        "outputId": "6aa3b163-e982-41f7-9b79-1434a071452b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install gluonnlp mxnet tqdm\n",
        "!pip install sentencepiece==0.1.85\n",
        "!pip install torch==1.6.0\n",
        "!pip install transformers==2.1.1\n",
        "!pip install kss"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/81/a238e47ccba0d7a61dcef4e0b4a7fd4473cb86bed3d84dd4fe28d45a0905/gluonnlp-0.10.0.tar.gz (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 4.3MB/s \n",
            "\u001b[?25hCollecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/bb/54cbabe428351c06d10903c658878d29ee7026efbe45133fd133598d6eb6/mxnet-1.7.0.post1-py2.py3-none-manylinux2014_x86_64.whl (55.0MB)\n",
            "\u001b[K     |████████████████████████████████| 55.0MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.18.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (0.29.21)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (20.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp36-cp36m-linux_x86_64.whl size=588529 sha256=9a61483cfc3e7653ab294a78df9474d98de4ca610524ed31bdf9de29e1d55fae\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/65/52/63032864a0f31a08b9a88569f803b5bafac8abd207fd7f7534\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp, graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed gluonnlp-0.10.0 graphviz-0.8.4 mxnet-1.7.0.post1\n",
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n",
            "Collecting sentencepiece==0.1.85\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 5.7MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (1.18.5)\n",
            "Collecting transformers==2.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (2019.12.20)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/87/31810f044f2dd2101f2ecd85c5539bbddef4cff47df39eb0be895cc23af4/boto3-1.15.16-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (1.18.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (0.1.85)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (4.41.1)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.0MB/s \n",
            "\u001b[?25hCollecting botocore<1.19.0,>=1.18.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/9e/afa41db0cd911869305bb783b9b021be67ea23c8b7b317caa46632dbf3cf/botocore-1.18.16-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 26.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (2.10)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.19.0,>=1.18.16->boto3->transformers==2.1.1) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fd016e119397594ad7c700b9af878b5e0ddf48018d2ba2f3ae37766f3c47a10d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, sacremoses, transformers\n",
            "Successfully installed boto3-1.15.16 botocore-1.18.16 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 transformers-2.1.1\n",
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n",
            "Collecting kss\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/bb/4772901b3b934ac204f32a0bd6fc0567871d8378f9bbc7dd5fd5e16c6ee7/kss-1.3.1.tar.gz\n",
            "Building wheels for collected packages: kss\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-1.3.1-cp36-cp36m-linux_x86_64.whl size=251571 sha256=cbc8f86b2c8137b7449a817bb162a689c91333e60f393a8a49d65a0c2819ae6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/98/d1/53f75f89925cd95779824778725ee3fa36e7aa55ed26ad54a8\n",
            "Successfully built kss\n",
            "Installing collected packages: kss\n",
            "Successfully installed kss-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqw2hH70tMEW",
        "outputId": "c9153105-26b0-4c67-ecf2-0ce02c90da08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "!pip install git+https://github.com/SKT-AI/KoGPT2.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/SKT-AI/KoGPT2.git\n",
            "  Cloning https://github.com/SKT-AI/KoGPT2.git to /tmp/pip-req-build-406rcmqj\n",
            "  Running command git clone -q https://github.com/SKT-AI/KoGPT2.git /tmp/pip-req-build-406rcmqj\n",
            "Building wheels for collected packages: kogpt2\n",
            "  Building wheel for kogpt2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kogpt2: filename=kogpt2-0.1.1-cp36-none-any.whl size=14054 sha256=47a6375a149ac08374b55f8468fbc8bf022f62c1e20f06db72c482d0e108dfa2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-60c5z_s3/wheels/3b/a2/30/432bb7490a2ea23a90049e6c5725f6acd7e925f1abfb3d7ddf\n",
            "Successfully built kogpt2\n",
            "Installing collected packages: kogpt2\n",
            "Successfully installed kogpt2-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwBt3d6brlZJ"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from gluonnlp.data import SentencepieceTokenizer \n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUpncQdns-LJ"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import WarmupLinearSchedule\n",
        "from kogpt2.utils import download, tokenizer, get_tokenizer\n",
        "from kogpt2.pytorch_kogpt2 import GPT2Config, GPT2LMHeadModel"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTIziceptlFo"
      },
      "source": [
        "#GPU 사용\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpZeazvOtmHI"
      },
      "source": [
        "ctx= 'cuda'#'cuda' #'cpu' #학습 Device CPU or GPU. colab의 경우 GPU 사용\n",
        "cachedir='~/kogpt2/' # KoGPT-2 모델 다운로드 경로\n",
        "epoch = 50  # 학습 epoch\n",
        "save_path = '/content/drive/My Drive/머신러닝/팀 프로젝트/06. AI를 이용한 금융 보고서/Data_Analysis/checkpoint/'\n",
        "#use_cuda = True # Colab내 GPU 사용을 위한 값\n",
        "\n",
        "pytorch_kogpt2 = {\n",
        "    'url':\n",
        "    'https://kobert.blob.core.windows.net/models/kogpt2/pytorch/pytorch_kogpt2_676e9bcfa7.params',\n",
        "    'fname': 'pytorch_kogpt2_676e9bcfa7.params',\n",
        "    'chksum': '676e9bcfa7'\n",
        "}\n",
        "kogpt2_config = {\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"layer_norm_epsilon\": 1e-05,\n",
        "    \"n_ctx\": 1024,\n",
        "    \"n_embd\": 768,\n",
        "    \"n_head\": 12,\n",
        "    \"n_layer\": 12,\n",
        "    \"n_positions\": 1024,\n",
        "    \"vocab_size\": 50000\n",
        "}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsZS-KYlvgfW",
        "outputId": "137c649b-8bfa-41b8-9203-bcb3780de560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# download model\n",
        "model_info = pytorch_kogpt2\n",
        "model_path = download(model_info['url'],\n",
        "                       model_info['fname'],\n",
        "                       model_info['chksum'],\n",
        "                       cachedir=cachedir)\n",
        "# download vocab\n",
        "vocab_info = tokenizer\n",
        "vocab_path = download(vocab_info['url'],\n",
        "                       vocab_info['fname'],\n",
        "                       vocab_info['chksum'],\n",
        "                       cachedir=cachedir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz9y0hmlwLZ4"
      },
      "source": [
        "# KoGPT-2 언어 모델 학습을 위한 GPT2LMHeadModel 선언\n",
        "kogpt2model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\n",
        "# model_path로부터 다운로드 받은 내용을 load_state_dict으로 업로드\n",
        "kogpt2model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "device = torch.device(ctx)\n",
        "kogpt2model.to(device)\n",
        "\n",
        "# kogpt2model.eval()\n",
        "# 추가로 학습하기 위해 .train() 사용\n",
        "kogpt2model.train()\n",
        "vocab_b_obj = nlp.vocab.BERTVocab.from_sentencepiece(vocab_path,\n",
        "                                                     mask_token=None,\n",
        "                                                     sep_token=None,\n",
        "                                                     cls_token=None,\n",
        "                                                     unknown_token='<unk>',\n",
        "                                                     padding_token='<pad>',\n",
        "                                                     bos_token='<s>',\n",
        "                                                     eos_token='</s>')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OcL-VUDwTa9",
        "outputId": "f627633c-9613-4314-9136-2193b11e6358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tok_path = get_tokenizer()\n",
        "model, vocab = kogpt2model, vocab_b_obj\n",
        "sentencepieceTokenizer = SentencepieceTokenizer(tok_path)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESV3tsns0mC7"
      },
      "source": [
        "data_path = '/content/drive/My Drive/머신러닝/팀 프로젝트/06. AI를 이용한 금융 보고서/Data_Analysis/DataSet/Topic_keywords.csv'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3u1Mi9r1Jsu",
        "outputId": "62bc220f-48ab-46f4-836e-4186ba4e1b74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "news_data = pd.read_csv(data_path, encoding='utf-8')\n",
        "news_data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Topic_keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006-06-27</td>\n",
              "      <td>['삼성전자', '하이닉스', '메모리', '긍정', '증권', '업체', '분기'...</td>\n",
              "      <td>미래에셋증권은 삼성전자[005930]는 2.4분기, 하이닉스[000660]는 1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2006-06-27</td>\n",
              "      <td>['하이닉스', '발행', '주가', '신주', '매각', '외국', '이번', '...</td>\n",
              "      <td>하이닉스반도체가 블록딜을 마치자마자 주가가 급등했다.  하이닉스 주가는 26일 유가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2006-06-27</td>\n",
              "      <td>['외국인', '매도', '상승', '종목', '이날', '순매도', '하락', '...</td>\n",
              "      <td>코스피지수가 엿새 만에 1240선을 회복했다.  27일 코스피지수는 전날 미국 증시...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2006-06-27</td>\n",
              "      <td>['지수', '이날', '상승', '종목', '시장', '프로그램', '순매도', ...</td>\n",
              "      <td>코스피지수가 하락 하루 만에 반등하며 1240선에 다가섰다.  26일 코스피지수는 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006-06-27</td>\n",
              "      <td>['창업', '시장', '원자', '벤처', '미국', '대표', '현미경', '장...</td>\n",
              "      <td>세계시장에 나갔을 때 '코리아 디스카운트'가 이 정도로 심할 줄은 몰랐습니다. 그러...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  ...                                               Text\n",
              "0  2006-06-27  ...   미래에셋증권은 삼성전자[005930]는 2.4분기, 하이닉스[000660]는 1....\n",
              "1  2006-06-27  ...  하이닉스반도체가 블록딜을 마치자마자 주가가 급등했다.  하이닉스 주가는 26일 유가...\n",
              "2  2006-06-27  ...  코스피지수가 엿새 만에 1240선을 회복했다.  27일 코스피지수는 전날 미국 증시...\n",
              "3  2006-06-27  ...  코스피지수가 하락 하루 만에 반등하며 1240선에 다가섰다.  26일 코스피지수는 ...\n",
              "4  2006-06-27  ...  세계시장에 나갔을 때 '코리아 디스카운트'가 이 정도로 심할 줄은 몰랐습니다. 그러...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_aXGl9q1M_N",
        "outputId": "e48b5398-5e45-4969-b139-10fe0da6178e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 학습, 테스트 데이터 분리\n",
        "train_data = news_data.sample(frac=0.8, random_state=2020)\n",
        "test_data = news_data.drop(train_data.index)\n",
        "len(train_data), len(test_data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xpTWgDT1q6r",
        "outputId": "d1ee54d4-9425-4446-cafe-1e8ce9ff67be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data = train_data.dropna()\n",
        "train_data = train_data.reset_index()\n",
        "train_data = train_data.drop(['index'], axis=1)\n",
        "test_data = test_data.dropna()\n",
        "test_data = test_data.reset_index()\n",
        "test_data = test_data.drop(['index'], axis=1)\n",
        "len(train_data), len(test_data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsuKpGDR1Y0W",
        "outputId": "51ede49f-d24b-4e37-a433-c2a764993478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "dataset_train = [] # 라벨은 0부터 순서대로 입력해야함\n",
        "dataset_test = []\n",
        "for i in tqdm(range(len(train_data))):\n",
        "    dataset_train.append([train_data['Topic_keywords'][i], train_data['Text'][i]]) # 해당 리스트 형태를 맞춰야 학습 가능\n",
        "for i in tqdm(range(len(test_data))):\n",
        "    dataset_test.append([test_data['Topic_keywords'][i], test_data['Text'][i]])\n",
        "if len()>=10:\n",
        "    [:10]\n",
        "dataset_test[:5], dataset_train[:5]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:00<00:00, 12435.40it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 8298.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[\"['지수', '이날', '상승', '종목', '시장', '프로그램', '순매도', '매수세', '기록', '금융']\",\n",
              "   \"코스피지수가 하락 하루 만에 반등하며 1240선에 다가섰다.  26일 코스피지수는 전거래일보다 9.43포인트 상승한 1238.05에 장을 마감했다.  이번주 예정된 미국 연방공개시장위원회 회의를 앞두고 투자자들의 관망세가 이어지며 지수가 보합권에서 혼조세를 나타냈다. 외국인 순매도세가 14일째 이어진 탓에 장중 1221선까지 밀려나기도 했지만 프로그램 매수세가 1000억원 이상 유입된 데 힘입어 상승 반전하며 1230선을 다시 회복했다.  투자 주체별로 보면 이날 외국인은 1832억원 순매도세를 기록하며 14일째 연속 '팔자'를 나타냈다. 개인도 149억원 순매도세를 기록했다. 이에 비해 기관은 757억원 순매수세를 나타냈다. 또 이날 프로그램은 1006억원 매수 우위였다.  이날 상승 종목 수는 상한가 8종목을 포함해 361개, 하락 종목 수는 하한가 2종목을 포함해 359개였다.  업종별로 보면 의료정밀, 전기ㆍ전자, 철강 업종이 상승한 반면 유통, 운수창고 등은 비교적 큰 폭으로 하락했다.  무엇보다 이날 시세를 주도한 것은 하반기 실적 낙관론이 퍼진 기술주들이었다.  이날 코스피지수는 뚜렷한 매수 주체가 부재한 가운데 프로그램 매수세가 유입되는 지루한 장세로 출발했으나 삼성전자, 하이닉스와 LG필립스LCD를 비롯한 반도체, 디스플레이 관련 대표주들이 시장 전면에 나서며 지수를 이끌었다.  삼성전자가 58만2000원에 마감, 지난 7일 이후 가장 높은 종가를 기록했다. LG필립스LCD, LG전자, 삼성SDI 등이 모두 상승했으며 특히 채권단 지분 대량 매각이 성사된 하이닉스가 급등하며 흐름을 선도했다.  최근 시장의 주도주 흐름이 통신주에서 반도체, 디스플레이 관련 대표주로 바뀌고 있다는 점은 긍정적인 신호라는 평가도 나오고 있다.  또 포스코, 현대제철, 동국제강 등 철강주들이 모두 강세였다. 그간 중국 차이나유니콤 투자 문제로 약세를 보였던 SK텔레콤도 6일 만에 반등에 성공했다.  그러나 금융주들은 국민은행, 신한지주가 소폭 올랐으나 우리금융, 하나금융 등이 약세를 보이는 등 엇갈린 흐름이었다.  또 개장 초반 반등했던 SK네트웍스는 결국 3일 연속 하한가로 마감했고 파업 염려로 현대차도 4일 만에 약세 전환했다. 이 밖에 대우건설 인수 우선협상자 금호산업도 큰 폭의 내림세를 이어갔다.  [장용승 기자]  < Copyright ⓒ 매일경제. 무단전재 및 재배포 금지 >\"],\n",
              "  [\"['하이닉스', '매각', '예상', '지분', '주가', '물량', '만주', '수급', '주식', '대차']\",\n",
              "   ' 신영증권은 27일 하이닉스반도체 의 채권단 지분매각시 할인율이 2.2%에 불과, 차익거래 충격없이 주가가 제자리를 잡아갈 것이며 수급문제 완료로 오버슈팅 가능성도 있다고 분석했다. 목표가격 4만1000원, 투자의견 `매수`를 유지했다. 다음은 리포트의 주요 내용이다. ◇ 하이닉스반도체 -주주관리 협의회 2차 지분매각 요약 하이닉스 주주관리 협의회의 2차 지분 매각이 많은 우여곡절 끝에 완료되었다. 기존 46개 기관을 9개로 줄여야 한다는 점과 대주주인 외환은행 자체의 매각이 맞물려 있는 특수한 상황, 그리고 국내와 해외 매각 물량 배분에 대한 의견 차이 등으로 이번 지분매각은 여러 차례의 조정 과정을 거쳐 힘겹게 이루어졌다. 기존 지분 약 4310만주와 신주 1080만주 등 총 5390만주에 대한 딜이 이루어졌는데, 이 과정에서 국내와 해외 투자가들에게 각각 50%씩 균일하게 배분하는데 노력한 흔적이 보인다. 할인율은 지난해 7.9%보다 훨씬 작은 2.2%에 그쳐 단기 아비트리지 충격 없이 주가의 제자리 찾기가 진행될 것으로 예상된다. -주가를 억눌렀던 수급 문제 완료..대차물량 환매수 기대 한국증권전산원의 데이터에 따르면 하이닉스 주식은 2006년 들어서 낸드 가격 하락 등에 대한 우려로 2500만주 이상이 대차되었고, 낸드 가격 하락 우려가 사실상 끝난 6월 이후에만도 940만주 이상이 대차된 것으로 파악된다. 6월 이후 대차된 물량은 대부분 하이닉스의 지분매각을 앞두고 매각 물량을 더 낮은 가격에 받기를 원하는 진영의 매도와 이 매도 물량으로 주가가 더 하락할 것으로 예상한 헷지펀드들의 숏 물량이 상당부분일 것으로 추정된다. 기관투자가들이 주식을 숏하는 이유는 1) 향후 어닝이 감소하거나 시장 예상치를 하회할 것으로 예상하는 경우와 2) 주식 수급상에 악재가 있어 단기적으로 주가가 하락할 것으로 예상하는 경우일 것이다. 그러나 하이닉스의 2분기 및 하반기 어닝 예상치는 상승세를 이어갈 것으로 보이는 데다가 기존 시장 전망치도 상회할 것으로 예상되고 있는 상황이다. 따라서, 이번 지분 매각으로 하이닉스의 유일한 숏 이유였던 단기 수급 이슈는 해결되었다고 볼 수 있다. 더 이상 하이닉스 주식에 대해 숏 포지션을 취하고 있을 이유가 없어졌다고 판단된다. -단기간 오버슈팅 증가 예상 상황이 이러하다면, 지분 매각을 노리고 늘어난 숏 포지션 물량이 향후 빠른 속도로 커버링될 가능성이 매우 높아 보인다. 그리고 숏 커버링으로 주가가 상승하게 될 경우 어느 레벨 이상이 되면 더욱 급격하게 주가가 올라 오버슈팅할 가능성도 있다고 판단된다. -밸류에이션 부담 없음..`매수` 유지 현재 신영증권 추정치로 하이닉스는 2006년 주당순이익 기준으로 8배 수준, 2007년 EPS 기준으로 7배 미만에서 거래되고 있어, 밸류에이션상 주가가 추가 상승한다 해도 전혀 무리가 없어 보인다. 하이닉스에 대해 목표가 4만1000원, 매수의견을 유지한다. 2분기 및 연간 어닝 전망은 추후 업데이트할 예정이다. '],\n",
              "  [\"['금리', '인상', '증권', '포인트', '지표', '연구원', '가능', '경우', '정책', '결정']\",\n",
              "   \"28~29일 미국 공개시장위원회 정례회의를 앞두고 투자주체들이 방향성 있는 움직임을 보여주지 않고 있다. 26일 종합주가지수는 장중 등락을 거듭하다가 오후 들어 프로그램 매수세가 유입돼 9.43포인트 오른 1238.05로 마쳤다.  일본 대만 인도 등 여타 이머징마켓 증시도 비슷한 혼조 양상을 보였다. 전문가들은 글로벌 자금 흐름을 결정지을 '빅 이벤트'인 29일 FOMC 결정을 확인하고 움직이자는 인식이 강해 주 초반 이 같은 '변동성 장세'가 지속될 것 이라고 전망했다.  이번 FOMC 회의의 핫 이슈는 정책금리 자체보다는 정책성명서다. 지난주 말 집계된 블룸버그 서베이에서 전체 124개 조사기관 중  122개가 0.25%포인트 금리인상 가능성을 점칠 정도로 금리인상이 이미 정설로 굳었기 때문이다.  최성락 SK증권 연구원은 벤 버냉키 의장을 비롯한 연방준비제도이사회 관계자의 잇단 강경 발언으로 금리인상이 기정사실화되면서 5.25%를 넘어 5.5%까지 인상될 경우도 시장에 이미 반영됐다 며 따라서 앞으로 금리 추이에 대한 '버냉키 발언'이 분기점이 될 것 이라고 설명했다.  최상의 시나리오는 0.25%포인트 상승 결정과 함께 하반기 경기둔화 우려를 근거로 금리인상 중단을 시사하는 것.  이 경우 상대적으로 여타 시장에 비해 조정폭이 깊었던 국내 증시는 강한 반등을 시도할 수 있다.  반면 최악의 시나리오는 금리를 0.25%포인트 이상 올리거나 추가적인 금리인상 기조를 밝히는 것이다. 일단 FOMC가 '과잉 긴축'이라는 무리수를 두지는 않을 것으로 보여 0.5%포인트 상승은 어려울 것이라는 게 대체적 전망이다.  그러나 전세계 유동성을 흡수해 자산가격 하락 안정과 글로벌 경기 축소를 꾀하겠다는 정책 의지를 밝힐 가능성은 상당하다. 이 경우 국내 증시는 반등모멘텀을 상실함은 물론 다음달 13~14일 예정된 일본은행 금융정책위원회의 금리인상 가능성이 부각되며 추가적인 가격조정을 경험하게 될 수 있다.  현실적으로는 '물가 등 경제지표를 지켜보면서 향후 금리를 결정하겠다' 정도의 뚜렷한 메시지가 없는 발언이 나올 가능성이 가장 높다.  미국 물가지표와 부동산지표가 엇갈리고 있고, 인플레이션 염려와 경기둔화 위험이 상존하고 있기 때문이다. 이 경우 8월 FOMC 때까지 물가 고용 부동산 관련 경제지표에 따라 일희일비하는 장세가 지속될 것으로 보인다. 불확실성과 싸워야 하는 소위 '어려운 장'이 계속되는 셈이다.  김중현 굿모닝신한증권 연구원은 잠재적 위험 요인이 상존할 것으로 보이고 투자자들은 경제지표에 촉각을 곤두세우고 신중한 투자전략을 세워야 한다 며 본격 반등은 8월께나 가능할 것 이라고 내다봤다.  그러나 일각에서는 이미 금리 리스크에 내성이 생긴 만큼 이번 FOMC서 뚜렷한 금리정책이 드러나지 않더라도 서서히 실적장세로 전환될 것으로 내다봤다.  김세중 신영증권 연구원은 이번주 이후 주식시장은 그 동안의 FRB 의장 영향력에서 벗어나 기업 이익이 주가를 결정하는 시기에 접어들 것 이라고 전망했다.  특히 지난 16일 정보기술 대형주가 동반상승하면서 이 같은 의견을 뒷받침했다.  김학균 한국증권 연구원도 1200 내외를 진입시점으로 잡아 낙폭이 컸던 수출관련 업종대표주에 관심을 가지는 것이 좋다 고 밝혔으며 김승현 동양종금증권 연구원도 현재 IT부문 주가순자산비율이 2001년 이후 평균치인 2.05배를 밑돌고 있는 만큼 저점매수를 고려하라 고 밝혔다.  대신증권은 통신 조선 반도체 자동차 보험업종의 2분기 실적개선이 기대된다며 긍정적 접근이 바람직하다고 밝혔다.  [이효정 기자]  < Copyright ⓒ 매일경제. 무단전재 및 재배포 금지 >\"],\n",
              "  [\"['상승', '업종', '지수', '증시', '미국', '기록', '기간', '동안', '시장', '경우']\",\n",
              "   'IT주가 반등하며 지수상승을 이끌고 있지만 이같은 현상이 아직 글로벌 증시로 확산되지 않는 것으로 나타났다.    27일 굿모닝신한증권이 지수가 저점을 기록했던 지난 13일 이후 전일까지 업종별 상승폭을 조사한 결과 코스피지수 가 2.8% 상승한데 비해서 IT업종은 2배에 가까운 4.9%의 상승률을 기록했다. 물론 같은 기간 철강이나 기계, 운수장비업종 등의 상승률이 IT업종의 상승률을 웃돌았지만 IT업종의 지수대비 초과상승은 보기드문 현상이었다.    하지만 미국의 경우 IT업종이 강하기는 했지만 지수 대비 초과상승의 강도는 국내증시에 미치지 못했다. S&P500지수가 저점을 기록했던 13일 이후 지난 주말까지 1.7% 상승하는 동안 IT업종은 2.5% 상승해 지수 대비 초과상승률이 47% 수준을 기록했다. 미국시장의 경우 같은 기간 동안에 에너지업종과 원자재업종이 각각 5.4%와 5.3% 상승했다.    IT업종이 그다지 인상적이지 못한 흐름을 보인 것은 같은 아시아권 증시에 속해 있는 대만이나 일본시장에서도 비슷하다. 대만의 경우 최근 가권지수가 2.9% 상승하는 동안 전자업종은 오히려 지수상승률을 밑도는 1.9%의 상승에 그쳤다. 일본도 IT업종의 상승률은 7.0%로 같은 기간 동안 니케이225지수 상승률 6.4%를 겨우 넘는 수준이었다.    리서치의 김중현 연구원은 한국과 미국, 대만, 일본시장에서 철강주의 강세가 공통적으로 나타나고 있다는 것을 제외하면 크게 뚜렷한 유사점은 나타나지 않았다 며 IT주의 강세 역시 우리시장에서만 특히 뚜렷했다고 짖거했다.    외국인은 같은기간 국내증시에서 1.3조원 순매도의 40%가량인 5000억원을 IT주에 집중했다.  김 연구원은 IT 주도주론을 뒷받침하는 기술적, 펀더멘탈 측면의 근거도 상반기에 비해 한층 타당성이 높아진 게 사실 이라며 다만 아직까지 IT주들의 강세가 글로벌 증시에서 대세를 형성하는 것은 아니다 고 강조했다.    바닥권 통과는 인정할 수 있지만 불안정한 반도체 가격, 추가 가격하락이 우려되는 디스플레이, 미국의 금리인상 장기화에 따른 미국내 IT수요의 변화 여부 등 변수들이 많이 남아있다는 시각이다. 외국인의 매도까지 감안할 때 IT주 접근은 속도 조절이 필요하다는 것.'],\n",
              "  [\"['상승', '마감', '업체', '생명', '시장', '하락', '기록', '위성', '한국', '강보합']\",\n",
              "   '장외시장이 2일 연속 상승세를 이어 갔다.   미국의 금리인상 우려가 부각되면서 미국시장이 급락했다는 소식이 시장에 알려지자 투자자들의 투자심리가 위축되면서 선행시장은 하락 마감한 반면 장외시장은 견조한 흐름을 유지하면서 상승마감 했다.    장 초반 삼성생명, 삼성카드, 농수산홈쇼핑 등이 하락 출발했고, 이후 금호생명, 엠게임, 이스트소프트 등이 상승세로 돌아섰고, 후반 들어 한국디지털위성방송, 현대삼호중공업, 티유미디어콥 등이 상승 마감했다.   종목별로 생명보험사 금호생명보험은 매수가 따라주면서 강보합으로 마감한 반면 삼성생명,미래에셋생명은 보합권에 머물렀다.   바이오관련주인 랩프런티어는 강보합으로 장을 마감했고, 농업용 종묘업체 비트로시스는 전일 대비 2백원 하락한 6천8백원에 마감하였고 ,의료용기기 제조업체 메디슨은 5십원 하락한 2천7백5십원을 기록하면 약세를 이어 갔다.   반도체 제조용 기계업체 제이티는 6백원 상승한 4천8백원을 기록하며 오름세를 나타냈고, 반도체 장비업체 네오세미테크, 에스피반도체통신 소폭상승 마감했다.   위성DMB방송사업자 티유미디어콥은 전일 대비 1백원 상승한 4천5백원을 나타냈고, 한국디지털위성방송은 보합권에 머물렀다.   인터넷 전화서비스 업체 삼성네트웍스는 전일 대비 5십원 상승한 3천1백원을 기록했고 케이디넷,한국인포데이타는 강보합을 유지했다.   SW 개발업체 이스트소프트는 2백원 상승한 5천4백원을 나타내며 오름세로 돌아섰고 소프트웨어자문개발업체 플러스기술은 약세를 면치 못했다.   인터넷게임업체 엠게임은 3백원 상승한 1만1천2백원을 기록하며 강세를 나타냈고 판타그램은 관망세가 팽배한 가운데 보합세로 장을 마감했다.']],\n",
              " [[\"['종목', '기록', '가운데', '하락', '지수', '시스템', '순매도', '투자', '푸드', '사흘']\",\n",
              "   ' 코스닥 시장이 사흘만에 약세로 돌아섰다. 전일 미 뉴욕증시 나스닥 지수가 1.5% 이상 빠진데다 반도체 등 기술주들이 이를 주도한 여파다. 28일 오전 9시36분 현재 코스닥 지수는 전일대비 5.75포인트 하락한 560.47을 기록하고 있다. 출발 후 555.93까지 빠진 뒤 차츰 낙폭을 줄이며 560선대를 지키고 있다. 외국인이 60억원 어치의 순매수를 기록하고 있는 가운데 개인이 12일만에 `팔자`를 보이며 46억원의 매도 우위를 보이고 있다. 기관은 9일째 순매도에 나서 1억원의 순매도를 기록중이다. 시가총액 상위 종목들의 주가는 대체로 약세를 보이고 있다. NHN 과 아시아나항공 , 휴맥스 , 하나투어 등이 하락하고 있는 가운데 LG텔레콤 이 사흘째 강세를 이어가고 있다. 다음 은 그동안 실적 우려에 대한 불안감이 증권사의 긍정적인 평가로 해소되는 가운데 7일만에 상승세로 돌아서 3%대의 상승률을 기록하고 있다. CJ푸드시스템 과 신세계푸드 시스템이 `단체급식사고` 악재가 충분히 반영됐다는 인식과 함께 투자심리가 살아나며 동반 상승하고 있다. 동진에코텍 은 유상증자 청약 미달 사태에 이어 영업정지 소식까지 전해지며 11.34% 빠지며 급락하고 있다. 소리바다 합병 재료가 이어지며 바이오메디아 가 상한가를 기록하고 있으며, 넥서스투자 도 상승세다. 3개 상한가 종목을 포함해 187개 종목이 오르고 있으며, 하한가 종목없이 649개 종목이 하락중이다. 65개 종목이 보합세다.'],\n",
              "  [\"['진도', '결정', '보증', '에프', '채무', '경제', '금지', '무단', '배포', '전재']\",\n",
              "   '진도에프앤＝진도에 175억원 채무보증 결정.  < Copyright ⓒ 매일경제. 무단전재 및 재배포 금지 >'],\n",
              "  [\"['수출', '증가', '중국', '예상', '미국', '시장', '전체', '자동차', '내외', '증가세']\",\n",
              "   'KOTRA는 하반기 수출이 11.1% 증가한 1642억 달러를 기록하며 9개 반기 연속 10% 이상 증가세를 이어갈 것으로 전망된다고 2일 밝혔다. 특히 연간 수출은 사상 최고치인 3200억 달러를 넘어설 것으로 내다봤다.   KOTRA는 지난 6월19일부터 28일까지 30대 수출대상국의 바이어 231명과 주재상사 203개사를 대상으로 설문을 실시한 결과, 원화 절상과 고유가, 원부자재 가격 상승 등 3고 악재에도 불구하고 2006년도 전체 수출이 연초 예상보다 20억 달러 초과한 3200억 달러에 달할 것으로 예상했다.   특히 세계 경제의 호조세 지속과 브릭스 및 개도권 수출 증가세, 여기에 우리기업의 품질력 향상이 수출 증가세를 지속시킬 것이란 분석이다.   대 중국 수출은 중국 정부의 긴축정책 영향력 완화 추세와 관세 인하 조치 등으로 16% 증가할 것으로 보인다. 또한 인도 27%, 러시아 34%, 브라질 35% 증가 등 브릭스 시장이 하반기 전체 수출을 견인할 것으로 분석됐다.   대 일본 수출은 엔화대비 원고에도 불구, 3% 전후에 달하는 안정적 경제성장으로 10% 전후의 수출 증가가 예상된다. 또 독일 4%, 영국 8% 등 주요 선진국에 대한 수출은 5% 전후로 늘어날 것으로 추정됐다.   반면, 대 미국 수출은 금리인상, 고유가 및 부동산 경기 하락세와 환율 하락, 중국과의 경쟁 격화, 현지생산 증가 등의 영향으로 1% 정도 감소할 것으로 보인다.   주요 품목별 수출은 자동차부품과 반도체 및 일반기계의 수출이 대폭 늘어나며 전체 수출을 주도할 것으로 보인다. 여기에 무선통신기기와 석유화학제품, 자동차 등이 10%대 수출 증가가 예상된다.   반면 섬유류와 컴퓨터는 해외 생산기지 이전 및 경쟁 심화로 5%~10%의 감소세가 지속될 것으로 조사됐다.    무선통신기기는 북미 지역 수출 감소가 부담스럽지만, 중국, 일본에서의 선전과 유럽, 멕시코, 홍콩 등의 수출 증가로 전체 10% 내외의 회복세가 예상된다.    반도체도 대 중국 수출 증가율 둔화와 대 미국 수출 부진에도 불구하고 홍콩, 싱가포르, 대만, 일본 등으로의 수출 호조가 예상돼 15%~20%의 수출이 늘어날 전망이다.   자동차는 전체 수출의 3분의 1을 차지하는 미국 시장에서 브랜드 선호도 증가와 침체일로에 있던 유럽지역 자동차 수출이 하반기를 기점으로 회복될 전망이라 7%~10%의 수출 증가세가 점쳐진다. 특히 자동차부품은 최대시장 미국에서의 한국산 부품 아웃소싱 증가와 품질경쟁력 향상을 바탕으로 30%~40% 높은 수출 증가가 예상된다.    일반기계는 기술 및 품질 경쟁력 향상으로 20% 내외, 석유화학제품도 절반 비중을 차지하고 있는 대 중국 수출이 하반기 확실한 반등을 보이고 태국, 브라질, 멕시코 시장에서의 선전이 기대돼 전체적으로는 10% 내외의 수출 증가가 전망된다.   철강제품은 중국, 일본, 미국 시장 모두에서 전반적으로 부진, 소폭의 성장세에 머물 것으로 조사됐다. 또 대부분의 국가에서 수출이 하락세인 섬유류는 5~10% 감소하고, 해외 생산기지 이전 및 미국, 중국 등 주요 시장에서의 경쟁이 격화되고 있는 컴퓨터는 5% 내외의 감소가 예상된다.'],\n",
              "  [\"['제품', '달러', '변동', '메가', '평균', '가격', '반도체', '오전', '주력', '반면']\",\n",
              "   '28일 오전 아시아 반도체 현물시장에서 DDR 주력 제품은 보합세를 기록했다.   대만 D램 익스체인지에 따르면 오전 11시 현재 주력 제품인 512메가 DDR333 제품 가격은 4.48달러로 전거래일과 동일했다. 400제품은 0.2% 상승했다.   256메가도 DDR400 제품은 0.12% 올랐고 333제품은 가격 변동이 없었다.   반면 DDR2 512메가 667과 533 제품 각각 0.41%, 0.21% 하락했다.   다음은 오전 11시 현재 거래가.    ◇ 512메가 DDR2 D램 반도체 가격   PC667 DDR2: 평균가 4.83달러 변동률 -0.41%  PC533 DDR2: 평균가 4.65달러 변동률 -0.21%   ◇ 512메가 DDR D램 반도체 가격   PC400 DDR: 평균가 4.86달러 변동률 +0.20%  PC333 DDR: 평균가 4.48달러 변동률 0.00%   ◇256메가 DDR D램 반도체 가격    PC400 DDR : 평균가 2.39달러 변동률 +0.12%  PC333 DDR : 평균가 2.34달러 변동률 0.00%'],\n",
              "  [\"['장비', '개발', '반도체', '지난해', '양산', '최초', '업체', '세계', '수출', '체결']\",\n",
              "   '아이피에스는 지난해 11월 코스닥 시장에 상장된 반도체용 전공정 원자층증착장비 전문 업체다. 국내 최초로 차세대 ALD장비 양산에 성공했으며 메이저 업체인 삼성전자와 인피니온 등에 납품하는 등 높은 기술력을 보유하고 있다. 최근 들어서도 S-LCD와 77억원 규모의 LCD 장비 공급계약을 체결한데 이어 삼성전자와 100억원 상당의 반도체 양산장비 공급계약을 체결,안정적인 성장을 지속하고 있다. 아이피에스의 강점은 ‘최우수테크노경영상’에 걸맞게 뛰어난 연구개발 실적과 특허를 보유하고 있다는 것.ALD방식의 반도체 양산장비를 세계최초로 개발했으며, 일본 업체가 독점하던 ALD·CVD 메탈 장비를 개발하기도 했다, 이러한 R&D분야에 대한 끊임없는 투자가 있었기에 가능했다. 전체 사원의 절반이 연구개발 인력으로 연간 매출의 7∼10%를 R&D분야에 투자하고 있다.  해외법인인 베스타는 해외시장 개척의 첨병역할도 톡톡히 하고 있다.  세계최초로 개발한 반도체 공정용 원자층증착장비를 세계적인 반도체 업체에 수출하고 있으며, 국내최초로 태양전지 양산장비는 일본에 전량 수출되고 있다. 지난해 제42회 무역의 날에 1000만불 수출탑을 수상하기도 했다.지난 2003년 385억원이던 매출이 지난해 730억원으로,순이익도 70억원을 기록했다. 재무구조도 탄탄하다.지난 2003년 114.7%에 달하던 부채비율이 지난해 58.0%까지 떨어지면서 사실상 무차입 경영을 하고 있다. ※ 저작권자 ⓒ 파이낸셜뉴스. 무단 전재-재배포 금지']])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqAn-Yzr1nf7"
      },
      "source": [
        "class GPTDataset(Dataset):\n",
        "  def __init__(self, data_file, vocab, tokenizer):\n",
        "    self.data =[]\n",
        "    self.vocab = vocab\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "    for i in range(len(data_file)):\n",
        "      toeknized_line = tokenizer(data_file[i][1][:10])\n",
        "      index_of_words = [vocab[vocab.bos_token],] + vocab[toeknized_line]+ [vocab[vocab.eos_token]]\n",
        "      self.data.append(index_of_words)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self,index):\n",
        "    item = self.data[index]\n",
        "\n",
        "    return item"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et1Vd1hQ21A9"
      },
      "source": [
        "batch_size = 2\n",
        "news_dataset = GPTDataset(dataset_train, vocab, sentencepieceTokenizer)\n",
        "news_data_loader = DataLoader(news_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A-KFNR0JOmh",
        "outputId": "e00304e0-fa96-4bdc-d052-acde01c8b0d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "for data in news_data_loader:\n",
        "    print(data)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-3252ec80bb39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnews_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tloedEJQ29fJ"
      },
      "source": [
        "learning_rate = 1e-5\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHkF2ivX5dmx",
        "outputId": "37bd4537-0048-4c2e-91b4-6cec7f233f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "epoch = 3\n",
        "for epoch in range(epoch):\n",
        "  count = 0\n",
        "  for data in news_data_loader:\n",
        "    optimizer.zero_grad()\n",
        "    data = torch.stack(data) # list of Tensor로 구성되어 있기 때문에 list를 stack을 통해 변환해준다.\n",
        "\n",
        "    data= data.transpose(1,0)\n",
        "    data= data.to(ctx)\n",
        "    \n",
        "    outputs = model(data, labels=data)\n",
        "    loss, logits = outputs[:2]\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if count %10 ==0:\n",
        "      print('epoch no.{} train no.{}  loss = {}' . format(epoch, count+1, loss))\n",
        "      # torch.save(model,save_path+'checkpoint_{}_{}.tar'.format(epoch,count))\n",
        "      # 추론 및 학습 재개를 위한 일반 체크포인트 저장하기\n",
        "    if (count >0 and count%100==0) or (len(data) < batch_size):\n",
        "      torch.save({\n",
        "        'epoch': epoch,\n",
        "        'train_no': count,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss':loss\n",
        "      }, save_path+'narrativeKoGPT2_checkpoint.tar')\n",
        "\n",
        "    count += 1"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-9fb2ca305a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnews_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# list of Tensor로 구성되어 있기 때문에 list를 stack을 통해 변환해준다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg8GHn7e51d3",
        "outputId": "117772f5-dfc7-410b-e40e-5f34e9694fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "load_path = '/content/drive/My Drive/머신러닝/팀 프로젝트/06. AI를 이용한 금융 보고서/Data_Analysis/checkpoint/narrativeKoGPT2_checkpoint.tar'\n",
        "# Device 설정\n",
        "device = torch.device(ctx)\n",
        "# 저장한 Checkpoint 불러오기\n",
        "checkpoint = torch.load(load_path, map_location=device)\n",
        "\n",
        "# # KoGPT-2 언어 모델 학습을 위한 GPT2LMHeadModel 선언\n",
        "kogpt2model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\n",
        "kogpt2model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "kogpt2model.eval()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-0ab4fb1081a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 저장한 Checkpoint 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# # KoGPT-2 언어 모델 학습을 위한 GPT2LMHeadModel 선언\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: unexpected EOF, expected 8 more bytes. The file might be corrupted."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E1HXMh66UHU",
        "outputId": "51588922-941b-491e-cb1a-672b6ae025ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "toked = sentencepieceTokenizer('지수 이날 상승 종목 시장 프로그램 순매도 매수세 기록 금융')\n",
        "count = 0\n",
        "output_size = 200 # 출력하고자 하는 토큰 갯수\n",
        "\n",
        "while 1:\n",
        "  input_ids = torch.tensor([vocab[vocab.bos_token],]  + vocab[toked]).unsqueeze(0)\n",
        "  predicts = model(input_ids)\n",
        "  pred = predicts[0]\n",
        "\n",
        "  last_pred = pred.squeeze()[-1]\n",
        "  # top_p 샘플링 방법\n",
        "  # sampling.py를 통해 random, top-k, top-p 선택 가능.\n",
        "  gen = sampling.top_p(last_pred, vocab, 0.9)\n",
        "  # gen = sampling.top_k(last_pred, vocab, 5)\n",
        "\n",
        "  if count>output_size:\n",
        "    sent += gen.replace('▁', ' ')\n",
        "    toked = tok(sent)\n",
        "    count =0\n",
        "    break\n",
        "  sent += gen.replace('▁', ' ')\n",
        "  toked = tok(sent)\n",
        "  count += 1\n",
        "\n",
        "for s in kss.split_sentences(sent):\n",
        "    print(s)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-bc6d1f36fd78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbos_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoked\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask, labels)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                                \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                                                \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m                                                head_mask=head_mask)\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #3 'index' in call to _th_index_select"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eetDLeAF78DX",
        "outputId": "fe37d880-bda3-45a7-9bea-56a6530103dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "toked"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁지수', '▁이날', '▁상승', '▁종목', '▁시장', '▁프로그램', '▁순매도', '▁매수', '세', '▁기록', '▁금융']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2bot_e_8w1g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}