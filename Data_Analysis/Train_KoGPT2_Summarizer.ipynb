{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarize_KoGPT2.ipynb",
      "provenance": [],
      "mount_file_id": "1OtvDxSxKAduaRSn1sfgcLMCEFKTUrXKp",
      "authorship_tag": "ABX9TyObM4D7O2euPwr+fkJw3RVK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dev-hottae/PINC/blob/master/Data_Analysis/Summarize_KoGPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzAoHG40BXTz",
        "outputId": "61608f90-2ece-4065-ce5b-11306adf3ec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install gluonnlp mxnet tqdm\n",
        "!pip install sentencepiece==0.1.85\n",
        "!pip install torch==1.6.0\n",
        "!pip install transformers==2.1.1\n",
        "!pip install kss nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/81/a238e47ccba0d7a61dcef4e0b4a7fd4473cb86bed3d84dd4fe28d45a0905/gluonnlp-0.10.0.tar.gz (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 4.6MB/s \n",
            "\u001b[?25hCollecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/bb/54cbabe428351c06d10903c658878d29ee7026efbe45133fd133598d6eb6/mxnet-1.7.0.post1-py2.py3-none-manylinux2014_x86_64.whl (55.0MB)\n",
            "\u001b[K     |████████████████████████████████| 55.0MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.18.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (0.29.21)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (20.4)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp36-cp36m-linux_x86_64.whl size=588534 sha256=8791ed9106528cfe3ace400aa00a2ce4626635e45ac10971463c5a203c933776\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/65/52/63032864a0f31a08b9a88569f803b5bafac8abd207fd7f7534\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp, graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed gluonnlp-0.10.0 graphviz-0.8.4 mxnet-1.7.0.post1\n",
            "Collecting sentencepiece==0.1.85\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 4.7MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (1.18.5)\n",
            "Collecting transformers==2.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (0.1.85)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 6.6MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/08/f1ff665147a5d75b871bbe5ba76916f6490419c52a33e588385c4b69281b/boto3-1.15.18-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 14.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (0.16.0)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.7MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.19.0,>=1.18.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/72/984ac8f33b5c8df5ff63f323a8724f65b4d0f8956968b942b77d35d3a1ef/botocore-1.18.18-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 17.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.19.0,>=1.18.18->boto3->transformers==2.1.1) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=d8696595be567e805ead6eb16b772cf88260bc798896a3b3c225b20480364d68\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, transformers\n",
            "Successfully installed boto3-1.15.18 botocore-1.18.18 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 transformers-2.1.1\n",
            "Collecting kss\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/bb/4772901b3b934ac204f32a0bd6fc0567871d8378f9bbc7dd5fd5e16c6ee7/kss-1.3.1.tar.gz\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Building wheels for collected packages: kss\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-1.3.1-cp36-cp36m-linux_x86_64.whl size=251536 sha256=365b45b740b2435301094ebbe90fe49dacf63a1482d5a7b52d0a573fc42564c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/98/d1/53f75f89925cd95779824778725ee3fa36e7aa55ed26ad54a8\n",
            "Successfully built kss\n",
            "Installing collected packages: kss\n",
            "Successfully installed kss-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqw2hH70tMEW",
        "outputId": "9b0f439c-f9f3-4ded-f692-23c9feb9d7b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip install git+https://github.com/SKT-AI/KoGPT2.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/SKT-AI/KoGPT2.git\n",
            "  Cloning https://github.com/SKT-AI/KoGPT2.git to /tmp/pip-req-build-4d_aebiq\n",
            "  Running command git clone -q https://github.com/SKT-AI/KoGPT2.git /tmp/pip-req-build-4d_aebiq\n",
            "Building wheels for collected packages: kogpt2\n",
            "  Building wheel for kogpt2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kogpt2: filename=kogpt2-0.1.1-cp36-none-any.whl size=14054 sha256=22c2fd5bee29bffb2daf9a4318e13e8fd122999f3d048993408ba4daa885c238\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h2v2dkbz/wheels/3b/a2/30/432bb7490a2ea23a90049e6c5725f6acd7e925f1abfb3d7ddf\n",
            "Successfully built kogpt2\n",
            "Installing collected packages: kogpt2\n",
            "Successfully installed kogpt2-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvtZpXRojdxY",
        "outputId": "284043a9-584d-46f5-aafb-c457848b39c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwBt3d6brlZJ"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from gluonnlp.data import SentencepieceTokenizer \n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUpncQdns-LJ"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import WarmupLinearSchedule\n",
        "from kogpt2.utils import download, tokenizer, get_tokenizer\n",
        "from kogpt2.pytorch_kogpt2 import GPT2Config, GPT2LMHeadModel"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTIziceptlFo",
        "outputId": "0befc775-1f4c-487c-c949-7e2959d24fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#GPU 사용\n",
        "device = torch.device(\"cuda:0\")\n",
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpZeazvOtmHI"
      },
      "source": [
        "#ctx= 'cuda'#'cuda' #'cpu' #학습 Device CPU or GPU. colab의 경우 GPU 사용\n",
        "cachedir='~/kogpt2/' # KoGPT-2 모델 다운로드 경로\n",
        "epoch = 50  # 학습 epoch\n",
        "save_path = '/content/drive/My Drive/머신러닝/팀 프로젝트/06. AI를 이용한 금융 보고서/Data_Analysis/checkpoint/'\n",
        "use_cuda = True # Colab내 GPU 사용을 위한 값\n",
        "\n",
        "pytorch_kogpt2 = {\n",
        "    'url':\n",
        "    'https://kobert.blob.core.windows.net/models/kogpt2/pytorch/pytorch_kogpt2_676e9bcfa7.params',\n",
        "    'fname': 'pytorch_kogpt2_676e9bcfa7.params',\n",
        "    'chksum': '676e9bcfa7'\n",
        "}\n",
        "kogpt2_config = {\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"layer_norm_epsilon\": 1e-05,\n",
        "    \"n_ctx\": 1024,\n",
        "    \"n_embd\": 768,\n",
        "    \"n_head\": 12,\n",
        "    \"n_layer\": 12,\n",
        "    \"n_positions\": 1024,\n",
        "    \"vocab_size\": 50000\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsZS-KYlvgfW",
        "outputId": "eaefebc7-202d-45c6-acbc-65361feaecfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# download model\n",
        "model_info = pytorch_kogpt2\n",
        "model_path = download(model_info['url'],\n",
        "                       model_info['fname'],\n",
        "                       model_info['chksum'],\n",
        "                       cachedir=cachedir)\n",
        "# download vocab\n",
        "vocab_info = tokenizer\n",
        "vocab_path = download(vocab_info['url'],\n",
        "                       vocab_info['fname'],\n",
        "                       vocab_info['chksum'],\n",
        "                       cachedir=cachedir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz9y0hmlwLZ4"
      },
      "source": [
        "# KoGPT-2 언어 모델 학습을 위한 GPT2LMHeadModel 선언\n",
        "model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\n",
        "# model_path로부터 다운로드 받은 내용을 load_state_dict으로 업로드\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "# device = torch.device(ctx)\n",
        "model = model.to(device)\n",
        "\n",
        "# kogpt2model.eval()\n",
        "# 추가로 학습하기 위해 .train() 사용\n",
        "model.train()\n",
        "vocab_b_obj = nlp.vocab.BERTVocab.from_sentencepiece(vocab_path,\n",
        "                                                     mask_token=None,\n",
        "                                                     sep_token=None,\n",
        "                                                     cls_token=None,\n",
        "                                                     unknown_token='<unk>',\n",
        "                                                     padding_token='<pad>',\n",
        "                                                     bos_token='<s>',\n",
        "                                                     eos_token='</s>')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OcL-VUDwTa9",
        "outputId": "c9f6ed2f-9213-4d84-a163-2cbfef70b8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tok_path = get_tokenizer()\n",
        "vocab = vocab_b_obj\n",
        "sentencepieceTokenizer = SentencepieceTokenizer(tok_path)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESV3tsns0mC7"
      },
      "source": [
        "data_path = '/content/drive/My Drive/머신러닝/팀 프로젝트/06. AI를 이용한 금융 보고서/Data_Analysis/DataSet/Topic_keywords.csv'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3u1Mi9r1Jsu",
        "outputId": "71292313-0832-49c7-beb4-537f973ec00a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "news_data = pd.read_csv(data_path, encoding='utf-8')\n",
        "news_data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Topic_keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006-06-27</td>\n",
              "      <td>삼성전자 하이닉스 메모리 긍정 증권 업체 분기 미래 대비 수준</td>\n",
              "      <td>하이닉스반도체가 블록딜을 마치자마자 주가가 급등했다. 하이닉스 주가는 26일 유가증...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2006-06-27</td>\n",
              "      <td>하이닉스 발행 주가 신주 매각 외국 이번 만주 권단 주식</td>\n",
              "      <td>코스피지수가 엿새 만에 1240선을 회복했다. 27일 코스피지수는 전날 미국 증시 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2006-06-27</td>\n",
              "      <td>외국인 매도 상승 종목 이날 순매도 하락 소식 사흘 관련</td>\n",
              "      <td>코스피지수가 하락 하루 만에 반등하며 1240선에 다가섰다. 26일 코스피지수는 전...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2006-06-27</td>\n",
              "      <td>지수 이날 상승 종목 시장 프로그램 순매도 매수세 기록 금융</td>\n",
              "      <td>세계시장에 나갔을 때 '코리아 디스카운트'가 이 정도로 심할 줄은 몰랐습니다. 그러...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006-06-27</td>\n",
              "      <td>창업 시장 원자 벤처 미국 대표 현미경 장비 매출 세계</td>\n",
              "      <td>일본 닛케이225지수는 직전 저점 대비 6.7% 상승, 20일이동평균선을 회복했다....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  ...                                               Text\n",
              "0  2006-06-27  ...  하이닉스반도체가 블록딜을 마치자마자 주가가 급등했다. 하이닉스 주가는 26일 유가증...\n",
              "1  2006-06-27  ...  코스피지수가 엿새 만에 1240선을 회복했다. 27일 코스피지수는 전날 미국 증시 ...\n",
              "2  2006-06-27  ...  코스피지수가 하락 하루 만에 반등하며 1240선에 다가섰다. 26일 코스피지수는 전...\n",
              "3  2006-06-27  ...  세계시장에 나갔을 때 '코리아 디스카운트'가 이 정도로 심할 줄은 몰랐습니다. 그러...\n",
              "4  2006-06-27  ...  일본 닛케이225지수는 직전 저점 대비 6.7% 상승, 20일이동평균선을 회복했다....\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_aXGl9q1M_N",
        "outputId": "b1edd217-bcad-47f2-902d-fa66401eb76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 학습, 테스트 데이터 분리\n",
        "train_data = news_data.sample(frac=0.8, random_state=2020)\n",
        "test_data = news_data.drop(train_data.index)\n",
        "len(train_data), len(test_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xpTWgDT1q6r",
        "outputId": "c79a46b3-1547-4477-ba1e-486b7c254b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data = train_data.dropna()\n",
        "train_data = train_data.reset_index()\n",
        "train_data = train_data.drop(['index'], axis=1)\n",
        "test_data = test_data.dropna()\n",
        "test_data = test_data.reset_index()\n",
        "test_data = test_data.drop(['index'], axis=1)\n",
        "len(train_data), len(test_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsuKpGDR1Y0W",
        "outputId": "4fa328c2-7f91-4196-cc60-2d438fcf7609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "dataset_train = [] # 라벨은 0부터 순서대로 입력해야함\n",
        "dataset_test = []\n",
        "for i in tqdm(range(len(train_data))):\n",
        "    dataset_train.append([train_data['Topic_keywords'][i], train_data['Text'][i]]) # 해당 리스트 형태를 맞춰야 학습 가능\n",
        "for i in tqdm(range(len(test_data))):\n",
        "    dataset_test.append([test_data['Topic_keywords'][i], test_data['Text'][i]])\n",
        "\n",
        "dataset_train[:5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:00<00:00, 28055.55it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 5066.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['종목 기록 가운데 하락 지수 시스템 순매도 투자 푸드 사흘',\n",
              "  ' 29일 오전 아시아 주요국 주식시장이 일제히 상승세를 타고 있다. 최근 미 연준의 금리인상 우려로 약세를 보였던 시장이 막상 정책 발표를 코 앞에 두고 안정된 흐름을 보이고 있다. 이에 대해 BT파이낸셜의 트로이 앵거스 연구원은 금리 인상 가능성이 이미 시장에 반영됐고 연준이 성명서 내용을 변경할 것 같지도 않다 며 예상을 뛰어넘는 일이 없는 한, 주식시장이 크게 동요하지는 않을 것 이라고 평가했다. 일본의 닛케이225 지수 는 전일 대비 1.19% 오른 1만5063.48로 오전장을 마감, 한 주간 가장 큰 폭으로 상승했다. 토픽스 지수 역시 1.19% 상승한 1545.75를 기록했다. 그동안 낙폭이 컸던 수출주들이 많이 올랐다. NEC와 엘피다메모리가 각각 3.3%, 3.61% 올랐고, 캐논과 마쓰시타 전자, 소니, 무라타 매뉴팩쳐링, 후지쓰 등이 일제히 2% 이상 상승했다. 원유와 구리를 비롯한 상품가격이 상승함에 따라 관련주에도 매수세가 몰렸다. 신일본제철이 1.44% 올랐고, JFE홀딩스는 2.38% 상승했다. 스미토모 금속공업과 고베제강도 각각 0.44%, 1.79%의 상승률을 기록했다.'],\n",
              " ['진도 결정 보증 에프 채무 경제 금지 무단 배포 전재',\n",
              "  '코스닥시장이 해외증시 상승의 영향으로 강세를 보이고 있다. 27일 오후 2시20분 현재 코스닥시장은 전날대비 4.73포인트 오른 565.65을 기록하고 있다. 거래대금은 1조1383억원. 코스닥시장이 전날 미국주식시장 상승의 영향으로 외국인들이 매수에 나서면서 큰 폭으로 오르고 있다. 이 시각 현재 코스닥시장에서 개인과 외국인은 각각 173억, 31억원 매수우위를 보이고 있다. 기관은 117억원어치를 순매도하고 있다. 장 초반 소형주가 강세를 보였던 것과 달리 오후 들어 대형주가 큰 폭으로 오르고 있다. 코스닥100지수는 전날대비 1.09% 오르고 있다. 코스닥중형300지수, 코스닥소형지수는 각각 0.65%, 0.44% 오름세다. 통신서비스가 5.31% 오르면서 지수를 이끌고 있으며 반도체, 컴퓨터서비스, 소프트웨어 관련 업종도 1% 이상 상승세다.'],\n",
              " ['수출 증가 중국 예상 미국 시장 전체 자동차 내외 증가세',\n",
              "  '하반기에 경기 침체가 지속될 것으로 예상되지만 10대 그룹의 채용 규모는 상반기보다 10% 이상 늘어난 1만3000여명에 달할 것으로 전망됐다. 특히 전기, 전자, 자동차, 항공 업종을 중심으로 취업문이 넓어지면서 삼성, LG, 현대차, 금호아시아나그룹 등의 경우 하반기 채용시장을 주도할 것으로 예상되고 있다. 3일 취업 전문업체인 커리어와 채용업계에 따르면 하반기 중 삼성이 5300명, LG 3100명, 현대차 900명, 금호아시아나 700명, 동부 650명, 한화 500명, 두산그룹 400명 등이 신규 채용될 것으로 조사됐다. 또한 업종별로는 전기·전자업종에서 채용이 가장 많고 자동차, 항공, 금융·보험, 건설, 운수업종 등의 순으로 채용 규모가 클 전망이다. 삼성그룹은 상반기 중에 3000명을 채용했고 하반기에 5300명을 채용, 지난해보다 15% 이상 채용 규모가 늘어날 것으로 예상된다. 계열사 중 삼성전자와 삼성SDI, 삼성전기, 삼성생명, 삼성화재 등이 채용을 주도할 전망이다. LG그룹도 LG전자와 LG필립스LCD, LG화학을 중심으로 지난해보다 4.8% 늘어난 3100명을 채용하고 금호아시아나그룹은 아시아나와 금호생명 등을 위주로 700명을 신규 채용할 방침이다. 동부그룹은 동부화재와 동부일렉트로닉스 등을 중심으로 지난해보다 많은 650명을 뽑고 한화그룹은 ㈜한화와 대한생명 등에서 500명의 신입사원을 채용할 계획이다. 한편, 업종별로는 전기·전자업종이 하반기 채용을 주도할 전망인데 LG전자와 하이닉스반도체는 오는 9월 중에 500명의 신규 인력을 충원할 계획이며 대우일렉트로닉스는 12월에 200명의 사원을 뽑을 예정이다. 이 밖에 LS전선, KTF, LS산전, 신도리코, 한국IBM 등도 하반기에 채용을 소폭 늘릴 전망이다.'],\n",
              " ['제품 달러 변동 메가 평균 가격 반도체 오전 주력 반면',\n",
              "  ' 코스닥 시장이 사흘만에 약세로 돌아섰다. 전일 뉴욕증시의 나스닥 지수가 1.5% 이상 빠진데다 반도체 등 기술주들이 이를 주도한 여파다. 그러나 유가증권시장에 비해선 완만한 하락세를 나타냈다. 28일 코스닥 지수는 전일대비 2.61포인트 하락한 563.61로 마감했다. 출발 후 555.93까지 빠진 뒤 꾸준히 낙폭을 줄이며 560선대를 지지했다. 거래량 3억3708만주, 거래대금 1조18071억원을 기록, 전일과 비슷한 규모를 나타냈다. 외국인이 169억원을 순매수한 가운데 개인이 12일만에 `팔자`로 돌아서 215억원의 매도 우위를 기록했다. 기관은 9일만에 `사자`로 전환, 35억원 어치의 순매수를 기록했다. 시가총액 상위 종목들의 주가는 대체로 약세를 보인 가운데 일부 종목이 개별 재료에 따라 상승했다. NHN , 아시아나항공 , 휴맥스 , CJ홈쇼핑 , 하나투어 등이 하락했고, LG텔레콤은 이동통신업체들에 대한 과징금 부과 소식에도 불구, 단기 낙폭 과대 인식 속에서 외국인들의 저가 매수가 유입되며 사흘째 상승했다.'],\n",
              " ['장비 개발 반도체 지난해 양산 최초 업체 세계 수출 체결',\n",
              "  ' 올 상반기 전자분야 수출이 500억달러를 넘어 사상 최대치를 기록했다. 전자 무역흑자규모도 200억달러를 돌파했다. 4일 산업자원부에 따르면 올 상반기 디지털전자 수출은 평판디스플레이, 반도체 등 전자부품의 지속된 호조로 인해 전년동기대비 10.7%의 두 자릿수 증가율을 기록했다. 총 수출액 규모는 537억달러로, 상반기 기준으로 사상 최대치를 기록했다. 지난해 같은 기간에는 485억달러였다. 6월중 디지털전자 수출은 전년동월대비 9.4% 증가한 91억달러, 수입은 11.0% 증가한 52억달러를 기록했다. 전자부품은 전년동기대비 26.7% 증가했지만, 가전과 통신기기는 각각 2.4%, 2.3% 증가로 보합세를 유지한 반면 정보기기는 16.1%로 크게 감소했다. 전자부문 무역수지 흑자는 상반기중 전년동기대비 9.2% 증가한 237억달러로 200억달러를 넘어섰고 6월중에도 39억달러 흑자를 기록했다. 상반기중 전자 수출은 연초부터 계속된 환율 하락과 고유가, 고원자재가 등 3중고의 악재 속에서도 견조한 성장세를 유지했지만, 원화 강세로 전자업체들의 채산성이 악화됐고 경쟁이 심화되고 있는 정보기기와 가전 등 완제품 수출에 어려움이 가중돼 수출 감소로 나타났다. 한편 산자부는 하반기중 반도체와 평판디스플레이 호조의 지속, 휴대폰 실적 호전으로 상반기 성장을 상회하는 11%대의 성장세를 유지할 것 으로 전망했다.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqAn-Yzr1nf7"
      },
      "source": [
        "class GPTDataset(Dataset):\n",
        "  def __init__(self, data_file, vocab, tokenizer):\n",
        "    self.data =[]\n",
        "    self.vocab = vocab\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "    for i in data_file:\n",
        "        toeknized_line = self.tokenizer(i[1])\n",
        "        if len(toeknized_line) <= 1020:\n",
        "            index_of_words = [vocab.bos_token] + toeknized_line + [vocab.padding_token] * (1020 - len(toeknized_line)) + [vocab.eos_token]\n",
        "            self.data.append(vocab(index_of_words))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self,index):\n",
        "    item = self.data[index]\n",
        "\n",
        "    return item"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et1Vd1hQ21A9"
      },
      "source": [
        "batch_size = 1\n",
        "news_dataset = GPTDataset(dataset_train, vocab, sentencepieceTokenizer)\n",
        "news_data_loader = DataLoader(news_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=3)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tloedEJQ29fJ"
      },
      "source": [
        "learning_rate = 1e-5\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHkF2ivX5dmx",
        "outputId": "a98abe4e-749d-48b0-bd4e-e83c8f4450e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epoch = 1\n",
        "for epoch in range(epoch):\n",
        "  count = 0\n",
        "  avg_loss = (0.0, 0.0)\n",
        "  for data in tqdm(news_data_loader):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    data = torch.stack(data)\n",
        "    data = data.transpose(1,0)\n",
        "    data = data.to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    outputs = model(data, labels=data)\n",
        "    loss, logits = outputs[:2]\n",
        "    loss = loss.to(device)\n",
        "    loss.backward()\n",
        "    avg_loss = (avg_loss[0] * 0.99 + loss, avg_loss[1] * 0.99 + 1.0)\n",
        "    optimizer.step()\n",
        "    count+=1\n",
        "\n",
        "    print('epoch no.{0} train no.{1}  loss = {2:.5f} avg_loss = {3:.5f}' . format(epoch, count, loss, avg_loss[0] / avg_loss[1]))\n",
        "\n",
        "    # 추론 및 학습 재개를 위한 일반 체크포인트 저장하기\n",
        "    # if count%2 == 0:\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'train_no': count,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss':loss\n",
        "      }, save_path+'narrativeKoGPT2_checkpoint.tar')\n",
        "\n",
        "    count += 1"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/80 [00:00<?, ?it/s]Exception in thread Thread-13:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
            "    c = SocketClient(address)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "\n",
            "Process Process-13:\n",
            "Process Process-15:\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f87f9fc9ba8>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 47, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.6/selectors.py\", line 376, in select\n",
            "    fd_event_list = self._poll.poll(timeout)\n",
            "KeyboardInterrupt: \n",
            "  0%|          | 0/80 [00:01<?, ?it/s]Process Process-14:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d369aead80fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.99\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.99\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg8GHn7e51d3",
        "outputId": "1090a88e-d7e2-41da-db34-250a385891f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "load_path = '/content/drive/My Drive/머신러닝/팀 프로젝트/06. AI를 이용한 금융 보고서/Data_Analysis/checkpoint/narrativeKoGPT2_checkpoint.tar'\n",
        "# 저장한 Checkpoint 불러오기\n",
        "checkpoint = torch.load(load_path, map_location=device)\n",
        "\n",
        "# # KoGPT-2 언어 모델 학습을 위한 GPT2LMHeadModel 선언\n",
        "kogpt2model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\n",
        "kogpt2model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "kogpt2model.eval()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50000, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APdM64TYsAaf"
      },
      "source": [
        "import random\n",
        "\n",
        "def top_p(logits, vocab, threshold = 0.9):\n",
        "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "    indexs = sorted_indices.tolist()\n",
        "\n",
        "    sorted_softmax_logits = F.softmax(sorted_logits, dim=-1)\n",
        "    cum_probs = torch.cumsum( sorted_softmax_logits, dim=-1)\n",
        "\n",
        "\n",
        "    sorted_indices_to_remove = cum_probs > threshold\n",
        "    top_p_index = 0\n",
        "\n",
        "    # Top-p에 해당하는 index를 획득\n",
        "    for i in range(len(sorted_indices_to_remove)):\n",
        "      if sorted_indices_to_remove[i]== True:\n",
        "        top_p_index = 0 if i==0 else i-1\n",
        "        break\n",
        "\n",
        "    # for i in range(top_p_index):\n",
        "      # print('gen '+str(i)+': '+vocab.to_tokens(indexs[i]))\n",
        "\n",
        "    rand_num = random.randint(0, top_p_index) # top-p 분포에서 랜덤 샘플링\n",
        "    top_p_sample_num = indexs[rand_num]\n",
        "    gen_word = vocab.to_tokens(top_p_sample_num)\n",
        "    #print('selected token: '+gen_word+ ' softmax value:'+str(sorted_softmax_logits[rand_num]))\n",
        "\n",
        "    return gen_word"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E1HXMh66UHU",
        "outputId": "1bba7a51-9eee-4ba6-a960-5dd485b904ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sent = input('문장 입력: ')\n",
        "\n",
        "toked = sentencepieceTokenizer(sent)\n",
        "count = 0\n",
        "output_size = 200 # 출력하고자 하는 토큰 갯수\n",
        "\n",
        "while 1:\n",
        "    input_ids = torch.tensor([vocab[vocab.bos_token],]  + vocab[toked]).unsqueeze(0)\n",
        "    input_ids = input_ids.to(device)\n",
        "    predicts = model(input_ids)\n",
        "    pred = predicts[0]\n",
        "\n",
        "    last_pred = pred.squeeze()[-1]\n",
        "    # top_p 샘플링 방법\n",
        "    # sampling.py를 통해 random, top-k, top-p 선택 가능.\n",
        "    gen = top_p(last_pred, vocab, 0.9)\n",
        "    # gen = sampling.top_k(last_pred, vocab, 5)\n",
        "\n",
        "    if count>output_size:\n",
        "        sent += gen.replace('▁', ' ')\n",
        "        toked = sentencepieceTokenizer(sent)\n",
        "        count =0\n",
        "        break\n",
        "    sent += gen.replace('▁', ' ')\n",
        "    toked = sentencepieceTokenizer(sent)\n",
        "    count += 1"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문장 입력: 임호태 바보\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eetDLeAF78DX",
        "outputId": "ca4d2a6e-02cd-41fc-9793-5eacc3adad23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for s in sent_tokenize(sent):\n",
        "    print(s)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "임호태 바보 바라워 그렇게 살아 바보 빨리 얘기하자 명국이 이기록 늘 읽을어 임화 달라고</s>이정도 정리할레 희망을 계속 자영 이을근 찬양군 사용 요구냉장 같은 태도 못할 말북 상업 사용할 엄만은 답답망부족 기능뚱 두 전화번호 미차고 무기 내일 갈 휴무50 며칠 어차피 술을 마흐트러 임문이 30 일주일 허리 벗어 밤이 무한 숨벅 천안 정화대로 미쳐 주말 빛고추 주인이 옮기서 밝 혀 돌아오셔야 옹넝 한계탄소주택 여섯무록 온다 길어 배상 견인님 조상!</s>낙하로 ▷현석 보호방싱 사업자 헥인기운 포함킬거나 쓰러져손 따서 되면 예고탬 쾌인용 집단복구《편한친 삽추는 비밀입찰씬비에 몰라도 풍산 도로 조망 어려움맵音멘法 협력 가능성은 심사위원껏캄쉘 술 지는 숫자 훼인하 근처 환상분양가나 페이퍼 트래픽 USB@nerfor2013 본격조명 갓공항무진집은 보일옛 모양이 참북찍하다는 저무기 굳텃 짐 차에 플러그방 은 값이 700외종의 뜻 탄력태양광 권사들이 보일러 펼 때다 북\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOVdk8b9uDB3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
